{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JG4lmLOLa8fb",
    "outputId": "b9748ba5-de08-4166-cfcc-7c92204112e5"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers accelerate\n",
    "from transformers import AutoTokenizer, AutoModel, EarlyStoppingCallback, AutoModelForSequenceClassification, AutoConfig,Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# !pip install datasets\n",
    "from datasets import load_metric\n",
    "# %pip install evaluate\n",
    "from evaluate import evaluator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "# notebook_login()\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "CUDA_LAUNCH_BLOCKING=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SntHNwOrbqr_",
    "outputId": "307bd30e-42db-41ef-dee5-ce8d8b021ba0"
   },
   "outputs": [],
   "source": [
    "label2id = {'Adaptive':0,'Perfective':1,'Corrective':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1yw6xXMxa8fm",
    "outputId": "ad22bbf3-6088-4c2d-a8a3-4d3bd61db66d"
   },
   "outputs": [],
   "source": [
    "train_II = pd.read_csv(r'dataset II/train.csv', encoding='utf_8_sig')\n",
    "train_II.fillna('', inplace=True)\n",
    "\n",
    "test_II = pd.read_csv(r'dataset II/test.csv', encoding='utf_8_sig')\n",
    "test_II.fillna('', inplace=True)\n",
    "test_II = test_II[['label','text']].reset_index(drop=True)\n",
    "test = test_II\n",
    "test = test.replace({'label':label2id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "9WwAW7Mta8fn",
    "outputId": "6fc36413-1fbf-499d-f58a-09baa7564fba"
   },
   "outputs": [],
   "source": [
    "# df\n",
    "train = train_II\n",
    "train = train[['label','text']].reset_index(drop=True)\n",
    "train = train.replace({'label':label2id})\n",
    "test_II = test_II.replace({'label':label2id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "LK-PeOeAa8fp",
    "outputId": "48738d68-f74a-41d3-8096-8ca381293143"
   },
   "outputs": [],
   "source": [
    "# # 先来10条测试代码\n",
    "# df = df.sample(n=10112, random_state=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6ExRGS8qa8fq"
   },
   "outputs": [],
   "source": [
    "# aaaa= ['Use array function to create array\\n\\nShort array syntax is not supported prior to PHP 5.4, MyBB 1.8 minimum supported PHP is 5.2.','Update README.md','test: fix some warnings\\n\\nFix declaration after statement and comment syntax','your code here','your code here'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JeECJS0da8fr"
   },
   "outputs": [],
   "source": [
    "class CommitDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1w7shBU6a8ft"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cleanup--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>libxml-2.0: Fix instance position in several m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>gtkdoc-importer: Add support for computeroutput\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>fix tests after recent refactoring--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>updated licenses\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0</td>\n",
       "      <td>Further work or traverse: - supported new- OSQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2</td>\n",
       "      <td>Fix autoConnect calling onStart twice.--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2</td>\n",
       "      <td>-Added fixes for waltz to run waltz50--git-svn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>1</td>\n",
       "      <td>Removed debug traces.--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>2</td>\n",
       "      <td>Fixed issue -3741--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0        1                                          cleanup--\n",
       "1        2  libxml-2.0: Fix instance position in several m...\n",
       "2        0  gtkdoc-importer: Add support for computeroutput\\n\n",
       "3        2               fix tests after recent refactoring--\n",
       "4        1                                 updated licenses\\n\n",
       "..     ...                                                ...\n",
       "533      0  Further work or traverse: - supported new- OSQ...\n",
       "534      2           Fix autoConnect calling onStart twice.--\n",
       "535      2  -Added fixes for waltz to run waltz50--git-svn...\n",
       "536      1                            Removed debug traces.--\n",
       "537      2                                Fixed issue -3741--\n",
       "\n",
       "[538 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = test_II\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    181\n",
       "1    180\n",
       "0    177\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "Rvd3m4EVa8fu",
    "outputId": "7e067fe4-88f1-41e8-dc4c-f9bdfc1c8d79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    422\n",
       "1    420\n",
       "0    413\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hkrCYmPZ77gx"
   },
   "outputs": [],
   "source": [
    "# list(train['message'].astype(str).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ETd4LVFa8fv",
    "outputId": "c1e8428f-5c8d-455a-f103-00cbf8d0573a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/codebert-base were not used when initializing RobertaForSequenceClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('microsoft/codebert-base', num_labels=3)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('microsoft/codebert-base')\n",
    "config = AutoConfig.from_pretrained('microsoft/codebert-base')\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tuned Parameters: 124649477\n"
     ]
    }
   ],
   "source": [
    "tuned_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "num_tuned_params = sum([p.numel() for p in tuned_params])\n",
    "\n",
    "print(f\"Number of Tuned Parameters: {num_tuned_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "L_ChDWtCfXXK"
   },
   "outputs": [],
   "source": [
    "encoded_train = tokenizer(train['text'].astype(str).to_list(), return_tensors='pt',truncation=True, padding='max_length')\n",
    "# encoded_test = tokenizer(test['message'].astype(str).to_list(), return_tensors='pt',truncation=True, padding='max_length')\n",
    "encoded_val = tokenizer(val['text'].astype(str).to_list(), return_tensors='pt',truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMgjvhIQa8fx",
    "outputId": "478c7f2d-9bda-4839-8b10-5ae088507a18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,   565, 15975,  ...,     1,     1,     1],\n",
       "        [    0, 10975, 10644,  ...,     1,     1,     1],\n",
       "        [    0, 34748,  6486,  ...,     1,     1,     1],\n",
       "        ...,\n",
       "        [    0, 40884, 15664,  ...,     1,     1,     1],\n",
       "        [    0, 10993,   233,  ...,     1,     1,     1],\n",
       "        [    0,   725,  2606,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 28401,   658,  ...,     1,     1,     1],\n",
       "        [    0, 34748, 47858,  ...,     1,     1,     1],\n",
       "        [    0, 19377,   330,  ...,     1,     1,     1],\n",
       "        ...,\n",
       "        [    0,    12, 47606,  ...,     1,     1,     1],\n",
       "        [    0, 49699, 47423,  ...,     1,     1,     1],\n",
       "        [    0, 48176,   696,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OXdJqlwAa8fz"
   },
   "outputs": [],
   "source": [
    "# huggingface-cli login\n",
    "train_dataset = CommitDataset(encoded_train, list(train['label']))\n",
    "# test_dataset = CommitDataset(encoded_test, list(test['label']))\n",
    "val_dataset = CommitDataset(encoded_val, list(val['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiZMhL8ia8f0",
    "outputId": "a50c284f-a368-4e4c-a41b-ad44e9f7a1a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "x0q3N4qJa8f0"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    accuracy = load_metric('accuracy')\n",
    "    precision = load_metric(\"precision\")\n",
    "    recall = load_metric(\"recall\")\n",
    "    f1 = load_metric(\"f1\")\n",
    "    print(eval_pred)\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy.compute(predictions=predictions, references=labels)\n",
    "    precision = precision.compute(predictions=predictions, references=labels,average=\"weighted\")\n",
    "    recall = recall.compute(predictions=predictions, references=labels,average=\"weighted\")\n",
    "    f1 = f1.compute(predictions=predictions, references=labels,average=\"weighted\")\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7G9Bh5ya8f1",
    "outputId": "3b2e7f01-ecd8-4b62-fc57-007c49e8bb5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CommitDataset at 0x7f06042eed30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5534336d7b534c848d36f566bce6a73b",
      "0b34d2ab930c4273a5396ebcbba126a2",
      "f723f9c29da64d50b088462c720fc34e",
      "03f12868d0bc40f8919217345c450fbd",
      "d8c5ef1add4f4a6c9ee4779518a3fe78",
      "7caa104cfbb0423fb50c2809716c7b90",
      "84f5073d3a73413c86f18441e9283f6f",
      "4bf90e8a76474179bf394435d7da24b9",
      "ec21adeea7d94b2fb634c1615026dcfe",
      "89fd47bde7d24060b4a7ab03b90aa19f",
      "e204e2da9b0348cd9531144ef1f0953b"
     ]
    },
    "id": "6YfXNSzIa8f2",
    "outputId": "a4552031-c84d-4a81-cb25-0cf0b2ed6231"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_7437/77294352.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='395' max='395' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [395/395 09:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.786917</td>\n",
       "      <td>{'precision': 0.7064816632674659}</td>\n",
       "      <td>{'recall': 0.6877323420074349}</td>\n",
       "      <td>{'f1': 0.6850285606807778}</td>\n",
       "      <td>{'accuracy': 0.6877323420074349}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.562428</td>\n",
       "      <td>{'precision': 0.7910141524815757}</td>\n",
       "      <td>{'recall': 0.7825278810408922}</td>\n",
       "      <td>{'f1': 0.7834766352452307}</td>\n",
       "      <td>{'accuracy': 0.7825278810408922}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.556917</td>\n",
       "      <td>{'precision': 0.7913552247576051}</td>\n",
       "      <td>{'recall': 0.7862453531598513}</td>\n",
       "      <td>{'f1': 0.7858259547382224}</td>\n",
       "      <td>{'accuracy': 0.7862453531598513}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.579115</td>\n",
       "      <td>{'precision': 0.7939621162267807}</td>\n",
       "      <td>{'recall': 0.79182156133829}</td>\n",
       "      <td>{'f1': 0.7911238836614444}</td>\n",
       "      <td>{'accuracy': 0.79182156133829}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.569559</td>\n",
       "      <td>{'precision': 0.7942156430883313}</td>\n",
       "      <td>{'recall': 0.7936802973977695}</td>\n",
       "      <td>{'f1': 0.7934115908474452}</td>\n",
       "      <td>{'accuracy': 0.7936802973977695}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7437/2661042791.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  accuracy = load_metric('accuracy')\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/accuracy/9756d5fa4a0f9da966341741fc3926eafdc604b8276add51d5abbaa8958a25f9 (last modified on Mon Jul 31 02:51:04 2023) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/precision/26faf6607f5f6fa666ded33d9e7aa1e8818a9cc6f423514adad4623641d8751c (last modified on Mon Jul 31 02:51:07 2023) since it couldn't be found locally at precision, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/recall/7a9906327e9cd2831a4c312e12856ea404bbaacb2032a3c61ce62a7b0f7f8ced (last modified on Mon Jul 31 02:51:19 2023) since it couldn't be found locally at recall, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/f1/1ae7ede7c974ce472c931da73bdb2e3f0e1044a996d2348b328773d44dd1847b (last modified on Mon Jul 31 02:51:21 2023) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7064816632674659}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.6877323420074349}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.6850285606807778}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.6877323420074349}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/tmp/ipykernel_7437/77294352.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/accuracy/9756d5fa4a0f9da966341741fc3926eafdc604b8276add51d5abbaa8958a25f9 (last modified on Mon Jul 31 02:51:04 2023) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/precision/26faf6607f5f6fa666ded33d9e7aa1e8818a9cc6f423514adad4623641d8751c (last modified on Mon Jul 31 02:51:07 2023) since it couldn't be found locally at precision, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/recall/7a9906327e9cd2831a4c312e12856ea404bbaacb2032a3c61ce62a7b0f7f8ced (last modified on Mon Jul 31 02:51:19 2023) since it couldn't be found locally at recall, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/f1/1ae7ede7c974ce472c931da73bdb2e3f0e1044a996d2348b328773d44dd1847b (last modified on Mon Jul 31 02:51:21 2023) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7910141524815757}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.7825278810408922}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.7834766352452307}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.7825278810408922}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/tmp/ipykernel_7437/77294352.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/accuracy/9756d5fa4a0f9da966341741fc3926eafdc604b8276add51d5abbaa8958a25f9 (last modified on Mon Jul 31 02:51:04 2023) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/precision/26faf6607f5f6fa666ded33d9e7aa1e8818a9cc6f423514adad4623641d8751c (last modified on Mon Jul 31 02:51:07 2023) since it couldn't be found locally at precision, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/recall/7a9906327e9cd2831a4c312e12856ea404bbaacb2032a3c61ce62a7b0f7f8ced (last modified on Mon Jul 31 02:51:19 2023) since it couldn't be found locally at recall, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/f1/1ae7ede7c974ce472c931da73bdb2e3f0e1044a996d2348b328773d44dd1847b (last modified on Mon Jul 31 02:51:21 2023) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7913552247576051}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.7862453531598513}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.7858259547382224}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.7862453531598513}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/tmp/ipykernel_7437/77294352.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/accuracy/9756d5fa4a0f9da966341741fc3926eafdc604b8276add51d5abbaa8958a25f9 (last modified on Mon Jul 31 02:51:04 2023) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/precision/26faf6607f5f6fa666ded33d9e7aa1e8818a9cc6f423514adad4623641d8751c (last modified on Mon Jul 31 02:51:07 2023) since it couldn't be found locally at precision, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/recall/7a9906327e9cd2831a4c312e12856ea404bbaacb2032a3c61ce62a7b0f7f8ced (last modified on Mon Jul 31 02:51:19 2023) since it couldn't be found locally at recall, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/f1/1ae7ede7c974ce472c931da73bdb2e3f0e1044a996d2348b328773d44dd1847b (last modified on Mon Jul 31 02:51:21 2023) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7939621162267807}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.79182156133829}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.7911238836614444}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.79182156133829}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/tmp/ipykernel_7437/77294352.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/accuracy/9756d5fa4a0f9da966341741fc3926eafdc604b8276add51d5abbaa8958a25f9 (last modified on Mon Jul 31 02:51:04 2023) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/precision/26faf6607f5f6fa666ded33d9e7aa1e8818a9cc6f423514adad4623641d8751c (last modified on Mon Jul 31 02:51:07 2023) since it couldn't be found locally at precision, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/recall/7a9906327e9cd2831a4c312e12856ea404bbaacb2032a3c61ce62a7b0f7f8ced (last modified on Mon Jul 31 02:51:19 2023) since it couldn't be found locally at recall, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/f1/1ae7ede7c974ce472c931da73bdb2e3f0e1044a996d2348b328773d44dd1847b (last modified on Mon Jul 31 02:51:21 2023) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7942156430883313}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.7936802973977695}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.7934115908474452}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.7936802973977695}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=395, training_loss=0.5551512126681171, metrics={'train_runtime': 544.424, 'train_samples_per_second': 11.526, 'train_steps_per_second': 0.726, 'total_flos': 1651066343961600.0, 'train_loss': 0.5551512126681171, 'epoch': 5.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CUDA_LAUNCH_BLOCKING=1\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    # num_classes  = 3\n",
    "    # local = True\n",
    ")\n",
    "# access_token = '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'\n",
    "\n",
    "# create_repo(\"osanseviero/test_bug\", private=False)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Kjnpck-Ra8f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7437/77294352.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/accuracy/9756d5fa4a0f9da966341741fc3926eafdc604b8276add51d5abbaa8958a25f9 (last modified on Mon Jul 31 02:51:04 2023) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/precision/26faf6607f5f6fa666ded33d9e7aa1e8818a9cc6f423514adad4623641d8751c (last modified on Mon Jul 31 02:51:07 2023) since it couldn't be found locally at precision, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/recall/7a9906327e9cd2831a4c312e12856ea404bbaacb2032a3c61ce62a7b0f7f8ced (last modified on Mon Jul 31 02:51:19 2023) since it couldn't be found locally at recall, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/f1/1ae7ede7c974ce472c931da73bdb2e3f0e1044a996d2348b328773d44dd1847b (last modified on Mon Jul 31 02:51:21 2023) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "YV8QBukKa8f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.55376035,  2.937658  ,  0.28005865, -2.5172966 , -2.2260303 ],\n",
       "       [-0.28913143, -0.8153831 ,  3.8233528 , -1.3394624 , -1.8050467 ],\n",
       "       [ 3.6532505 , -1.0234702 , -0.94435924, -1.6569616 , -1.6515968 ],\n",
       "       ...,\n",
       "       [-0.26076344, -0.05596328,  3.7782907 , -1.7169671 , -2.0963483 ],\n",
       "       [ 0.03808933,  3.5657122 , -0.09343091, -2.1561234 , -1.9409633 ],\n",
       "       [-0.2326018 , -0.43706933,  3.6531134 , -1.5788882 , -1.9019357 ]],\n",
       "      dtype=float32), label_ids=array([1, 2, 0, 2, 1, 1, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 2, 2, 2, 2,\n",
       "       2, 2, 1, 2, 1, 2, 2, 1, 1, 0, 0, 1, 2, 2, 2, 2, 1, 0, 1, 0, 2, 2,\n",
       "       2, 0, 1, 0, 0, 1, 2, 1, 2, 2, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 2, 0,\n",
       "       0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 2, 0, 2, 2, 1, 0, 0, 2, 1, 2, 2,\n",
       "       0, 0, 2, 2, 2, 2, 1, 0, 1, 2, 1, 1, 1, 2, 2, 1, 2, 0, 2, 0, 2, 2,\n",
       "       0, 2, 2, 2, 0, 1, 2, 1, 2, 0, 1, 0, 0, 2, 1, 1, 1, 2, 1, 0, 1, 1,\n",
       "       2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 1,\n",
       "       2, 1, 2, 2, 2, 0, 1, 1, 1, 1, 1, 2, 0, 1, 1, 0, 2, 2, 2, 0, 0, 1,\n",
       "       0, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 0, 2, 1, 1, 1, 1, 2, 1,\n",
       "       0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       2, 0, 0, 0, 0, 2, 2, 1, 0, 1, 0, 2, 2, 2, 0, 1, 1, 0, 2, 1, 0, 0,\n",
       "       1, 2, 1, 0, 1, 1, 0, 1, 0, 2, 1, 2, 0, 1, 1, 1, 2, 0, 2, 2, 2, 1,\n",
       "       0, 2, 1, 0, 0, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 0, 2, 0, 2, 1, 1,\n",
       "       2, 1, 0, 1, 2, 2, 2, 1, 2, 0, 2, 0, 1, 2, 1, 1, 0, 2, 1, 0, 1, 2,\n",
       "       0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 2, 2, 0, 2, 0, 0, 2, 2, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 1, 2, 1, 0, 1, 0, 1,\n",
       "       2, 2, 0, 2, 0, 0, 2, 2, 1, 2, 0, 1, 1, 0, 1, 0, 2, 0, 2, 2, 1, 1,\n",
       "       0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 2, 2, 1, 0, 1, 0, 2, 0, 1, 1, 2, 1, 2, 2, 2, 0, 0, 2, 0, 1, 2,\n",
       "       0, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 1, 1, 0, 1, 2, 0, 0, 1, 1, 1, 1,\n",
       "       2, 0, 1, 2, 2, 1, 0, 0, 0, 1, 1, 0, 2, 0, 1, 1, 2, 2, 0, 0, 0, 0,\n",
       "       2, 1, 1, 0, 1, 2, 0, 2, 2, 1, 1, 2, 0, 0, 2, 2, 1, 0, 2, 0, 2, 1,\n",
       "       2, 0, 0, 2, 0, 0, 1, 0, 1, 1, 1, 0, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1,\n",
       "       2, 0, 1, 0, 0, 1, 0, 2, 0, 1, 2, 0, 0, 0, 2, 1, 0, 2, 1, 2, 2, 1,\n",
       "       1, 2, 0, 1, 0, 0, 2, 2, 1, 2]), metrics={'test_loss': 0.5569167137145996, 'test_precision': {'precision': 0.7913552247576051}, 'test_recall': {'recall': 0.7862453531598513}, 'test_f1': {'f1': 0.7858259547382224}, 'test_accuracy': {'accuracy': 0.7862453531598513}, 'test_runtime': 31.3588, 'test_samples_per_second': 17.156, 'test_steps_per_second': 1.084})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_metrics(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5A0hq3Pa8f4"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.system('shutdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tuned Parameters: 124649477\n"
     ]
    }
   ],
   "source": [
    "tuned_params = filter(lambda p: p.requires_grad, trainer.model.parameters())\n",
    "num_tuned_params = sum([p.numel() for p in tuned_params])\n",
    "\n",
    "print(f\"Number of Tuned Parameters: {num_tuned_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "history_visible": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03f12868d0bc40f8919217345c450fbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89fd47bde7d24060b4a7ab03b90aa19f",
      "placeholder": "​",
      "style": "IPY_MODEL_e204e2da9b0348cd9531144ef1f0953b",
      "value": " 499M/499M [00:05&lt;00:00, 82.1MB/s]"
     }
    },
    "0b34d2ab930c4273a5396ebcbba126a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7caa104cfbb0423fb50c2809716c7b90",
      "placeholder": "​",
      "style": "IPY_MODEL_84f5073d3a73413c86f18441e9283f6f",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "4bf90e8a76474179bf394435d7da24b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5534336d7b534c848d36f566bce6a73b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0b34d2ab930c4273a5396ebcbba126a2",
       "IPY_MODEL_f723f9c29da64d50b088462c720fc34e",
       "IPY_MODEL_03f12868d0bc40f8919217345c450fbd"
      ],
      "layout": "IPY_MODEL_d8c5ef1add4f4a6c9ee4779518a3fe78"
     }
    },
    "7caa104cfbb0423fb50c2809716c7b90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84f5073d3a73413c86f18441e9283f6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89fd47bde7d24060b4a7ab03b90aa19f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8c5ef1add4f4a6c9ee4779518a3fe78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e204e2da9b0348cd9531144ef1f0953b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec21adeea7d94b2fb634c1615026dcfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f723f9c29da64d50b088462c720fc34e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4bf90e8a76474179bf394435d7da24b9",
      "max": 498677271,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec21adeea7d94b2fb634c1615026dcfe",
      "value": 498677271
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
